{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import top_k_accuracy_score\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import random\n",
    "from scipy import stats\n",
    "#import statsmodels.api as sm\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from itertools import cycle\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, auc, roc_curve, roc_auc_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list999 = []\n",
    "list88 = []\n",
    "elselist = []\n",
    "column_feature = []\n",
    "accuracy = [] \n",
    "count0 = [] \n",
    "count1 = []\n",
    "print_list = []\n",
    "ct = 0\n",
    "def perf_measure(y_actual, y_hat):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==y_hat[i]==1:\n",
    "           TP += 1\n",
    "        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
    "           FP += 1\n",
    "        if y_actual[i]==y_hat[i]==0:\n",
    "           TN += 1\n",
    "        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
    "           FN += 1\n",
    "\n",
    "    return(TP, FP, TN, FN)\n",
    "\n",
    "\n",
    "# # 혈액검사 변수\n",
    "# column_name_gb = ['HE_BMI']\n",
    "# column_name_choice1 = ['HE_WBC', 'HE_RBC', 'HE_Bplt', 'HE_Uacid', 'HE_glu', 'HE_sbp', 'HE_dbp', 'HE_HbA1c', 'BE3_76', 'BE3_86', 'HE_TG', 'HE_ast', 'HE_alt', 'HE_HB']\n",
    "# column_name_6079 = ['HE_glu', 'HE_HbA1c', 'HE_alt', 'HE_TG', 'HE_RBC', 'HE_Uacid', 'HE_HB', 'HE_WBC', 'BE3_86', 'HE_ast']\n",
    "# column_name_1939 = ['HE_alt', 'HE_Uacid', 'HE_sbp', 'HE_glu', 'HE_TG', 'HE_HbA1c', 'HE_dbp', 'BE3_76', 'HE_WBC', 'HE_Bplt']\n",
    "# column_name_4059 = ['HE_TG', 'HE_alt', 'HE_glu', 'HE_Uacid', 'HE_HbA1c', 'HE_dbp', 'HE_sbp', 'HE_RBC', 'HE_WBC', 'HE_HB']\n",
    "# ######## \n",
    "# column_name_group = ['HE_BMI'] + column_name_choice1\n",
    "\n",
    "# # for c_name in column_name_gb + column_name_choice1 + column_name_6079 + column_name_1939 + column_name_4059:\n",
    "# #        if c_name not in column_name_group:\n",
    "# #          column_name_group.append(c_name)\n",
    "\n",
    "# # 아래에서 BMI를 기준으로 정렬하고, BMI를 제거하기 때문에 각 그룹별로 보기 위해서는 + ['HE_BMI'] 부분이 들어가야함.\n",
    "# column_feature = [column_name_gb + column_name_choice1,\n",
    "#                   column_name_gb + column_name_6079,\n",
    "#                   column_name_gb + column_name_1939,\n",
    "#                   column_name_gb + column_name_4059]\n",
    "\n",
    "# print_name = ['choice1', 5979, 1939, 3959]\n",
    "# cl = len(column_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "702\n",
      "1365\n",
      "1365\n",
      "1365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bm990\\Desktop\\백업\\Python_Code\\Obesity\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782\n",
      "2106\n",
      "2106\n",
      "2106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bm990\\Desktop\\백업\\Python_Code\\Obesity\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "845\n",
      "1587\n",
      "1587\n",
      "1587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bm990\\Desktop\\백업\\Python_Code\\Obesity\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1317\n",
      "697\n",
      "1317\n",
      "1317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bm990\\Desktop\\백업\\Python_Code\\Obesity\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1712\n",
      "1783\n",
      "1783\n",
      "1783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bm990\\Desktop\\백업\\Python_Code\\Obesity\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1039\n",
      "2013\n",
      "2013\n",
      "2013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bm990\\Desktop\\백업\\Python_Code\\Obesity\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "708\n",
      "1326\n",
      "1326\n",
      "1326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bm990\\Desktop\\백업\\Python_Code\\Obesity\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782\n",
      "2106\n",
      "2106\n",
      "2106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bm990\\Desktop\\백업\\Python_Code\\Obesity\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "845\n",
      "1587\n",
      "1587\n",
      "1587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bm990\\Desktop\\백업\\Python_Code\\Obesity\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1309\n",
      "701\n",
      "1309\n",
      "1309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bm990\\Desktop\\백업\\Python_Code\\Obesity\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1713\n",
      "1779\n",
      "1779\n",
      "1779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bm990\\Desktop\\백업\\Python_Code\\Obesity\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1037\n",
      "2011\n",
      "2011\n",
      "2011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bm990\\Desktop\\백업\\Python_Code\\Obesity\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "708\n",
      "1326\n",
      "1326\n",
      "1326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bm990\\Desktop\\백업\\Python_Code\\Obesity\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "780\n",
      "2079\n",
      "2079\n",
      "2079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bm990\\Desktop\\백업\\Python_Code\\Obesity\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "838\n",
      "1580\n",
      "1580\n",
      "1580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bm990\\Desktop\\백업\\Python_Code\\Obesity\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1309\n",
      "701\n",
      "1309\n",
      "1309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bm990\\Desktop\\백업\\Python_Code\\Obesity\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1717\n",
      "1766\n",
      "1766\n",
      "1766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bm990\\Desktop\\백업\\Python_Code\\Obesity\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1037\n",
      "2010\n",
      "2010\n",
      "2010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bm990\\Desktop\\백업\\Python_Code\\Obesity\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704\n",
      "1325\n",
      "1325\n",
      "1325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bm990\\Desktop\\백업\\Python_Code\\Obesity\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "780\n",
      "2079\n",
      "2079\n",
      "2079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bm990\\Desktop\\백업\\Python_Code\\Obesity\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "831\n",
      "1566\n",
      "1566\n",
      "1566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bm990\\Desktop\\백업\\Python_Code\\Obesity\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "c:\\Users\\bm990\\Desktop\\백업\\Python_Code\\Obesity\\.venv\\lib\\site-packages\\ipykernel_launcher.py:208: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "c:\\Users\\bm990\\Desktop\\백업\\Python_Code\\Obesity\\.venv\\lib\\site-packages\\ipykernel_launcher.py:225: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1305\n",
      "702\n",
      "1305\n",
      "1305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bm990\\Desktop\\백업\\Python_Code\\Obesity\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1717\n",
      "1766\n",
      "1766\n",
      "1766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bm990\\Desktop\\백업\\Python_Code\\Obesity\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1037\n",
      "2010\n",
      "2010\n",
      "2010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bm990\\Desktop\\백업\\Python_Code\\Obesity\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706\n",
      "1322\n",
      "1322\n",
      "1322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bm990\\Desktop\\백업\\Python_Code\\Obesity\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778\n",
      "2073\n",
      "2073\n",
      "2073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bm990\\Desktop\\백업\\Python_Code\\Obesity\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "831\n",
      "1566\n",
      "1566\n",
      "1566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bm990\\Desktop\\백업\\Python_Code\\Obesity\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1308\n",
      "698\n",
      "1308\n",
      "1308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bm990\\Desktop\\백업\\Python_Code\\Obesity\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1717\n",
      "1766\n",
      "1766\n",
      "1766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bm990\\Desktop\\백업\\Python_Code\\Obesity\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1037\n",
      "2010\n",
      "2010\n",
      "2010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bm990\\Desktop\\백업\\Python_Code\\Obesity\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAECCAYAAADXWsr9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAFmUlEQVR4nO3bPYsedRvG4esywSZtttLFtRAh9eJniJWtqYVUdmn8IjYpglUUSwvB1sbCTaeIEIRgLOKKXRoRrqdJkScWOxtnduKex9Hdw/LfE2Z/zL1vPTMFXG6v7T0A2J7QIYDQIYDQIYDQIYDQIYDQz6G7b3b3z939sLs/2XsPy3X3ve7+vbt/2HvLHoS+UHdfqapPq+r9qrpRVbe6+8a+qziHz6rq5t4j9iL05d6rqocz88vM/FVVX1TVBztvYqGZ+baq/tx7x16EvtwbVfXrc68fP7sGrzyhQwChL/dbVR0+9/rNZ9fglSf05b6vqne6++3ufr2qPqyqr3beBIsIfaGZ+buqPq6qb6rqp6r6cmZ+3HcVS3X351X1XVW9292Pu/ujvTddpPZvqnD5eaJDAKFDAKFDAKFDAKFDAKGfU3ff3nsDLy/1/gn9/CK/UC6RyPsndAiwyR/MXL9+fY6OjlY/91VwenpaBwcHe8/Y1IMHD/aewL8wM/3itatbfKKjo6M6OTnZ4mguQPc/vk74j/PWHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQIsCr27b3b3z939sLs/2XoUsK4zQ+/uK1X1aVW9X1U3qupWd9/YehiwniVP9Peq6uHM/DIzf1XVF1X1wbazgDUtCf2Nqvr1udePn10D/iNW+2Fcd9/u7pPuPjk9PV3rWGAFS0L/raoOn3v95rNr/2dm7s7M8cwcHxwcrLUPWMGS0L+vqne6++3ufr2qPqyqr7adBazp6lkfMDN/d/fHVfVNVV2pqnsz8+Pmy4DVnBl6VdXMfF1VX2+8BdiIv4yDAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAD0zqx96eHg4d+7cWf1cLsajR4/2nsBLun//fj158qRfvO6JDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgHODL2773X37939w0UMAta35In+WVXd3HgHsKEzQ5+Zb6vqzwvYAmzE9+gQYLXQu/t2d59098nTp0/XOhZYwWqhz8zdmTmemeNr166tdSywAm/dIcCSX699XlXfVdW73f24uz/afhawpqtnfcDM3LqIIcB2vHWHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAD0z6x/afVpVj1Y/+NVwvar+2HsEL+2y37+3ZubgxYubhH6ZdffJzBzvvYOXk3r/vHWHAEKHAEI/v7t7D+Bfibx/vkeHAJ7oEEDoEEDoEEDoEEDoEOB/zNK3OjhspEEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAECCAYAAADXWsr9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAFk0lEQVR4nO3bsWpedRjH8eexIVfQTCrGQYSuDV5DnVwtdBM6eQHeiEuH4qY4OgiuLg4mm1KEIoh1MeIFiPC4dKhVyEk9J6fm9/ls50/454HzfvM/b/KmZ6aA6+2VvQcAtid0CCB0CCB0CCB0CCB0CCD0S+juO939Q3c/7u6P9p6H5br7YXf/2t3f7T3LHoS+UHffqKqPq+rdqrpVVXe7+9a+U3EJn1TVnb2H2IvQl3unqh7PzI8z80dVfVZV7+08EwvNzNdV9fvec+xF6Mu9WlU/P3P95OkavPSEDgGEvtwvVfX6M9evPV2Dl57Ql/u2qt7q7je7+7Cq3q+qL3aeCRYR+kIz82dVfVhVX1XVo6r6fGa+33cqluruT6vqm6p6u7ufdPcHe890ldq/qcL150SHAEKHAEKHAEKHAEKHAEK/pO6+v/cMvLjU+yf0y4t8oVwjkfdP6BBgkw/M3Lx5c46Pj1ff92Vwfn5eR0dHe4+xqbOzs71H4D+YmX5+7WCLb3R8fFynp6dbbM0V6P7H64T/OY/uEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEGBR6N19p7t/6O7H3f3R1kMB67ow9O6+UVUfV9W7VXWrqu52962tBwPWs+REf6eqHs/MjzPzR1V9VlXvbTsWsKYlob9aVT8/c/3k6RrwP7HaL+O6+353n3b36fn5+VrbAitYEvovVfX6M9evPV37m5l5MDMnM3NydHS01nzACpaE/m1VvdXdb3b3YVW9X1VfbDsWsKaDi75gZv7s7g+r6ququlFVD2fm+80nA1ZzYehVVTPzZVV9ufEswEZ8Mg4CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CHGyx6aNHj+r27dtbbM0VODs723sEXtC9e/f+dd2JDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgEuDL27H3b3r9393VUMBKxvyYn+SVXd2XgOYEMXhj4zX1fV71cwC7AR79EhwMFaG3X3/aq6X1V1eHi41rbAClY70WfmwcyczMzJwcFqPz+AFXh0hwBL/rz2aVV9U1Vvd/eT7v5g+7GANV34jD0zd69iEGA7Ht0hgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhgNAhQM/M+pt2n1fVT6tv/HK4WVW/7T0EL+y63783Zubo+cVNQr/Ouvt0Zk72noMXk3r/PLpDAKFDAKFf3oO9B+A/ibx/3qNDACc6BBA6BBA6BBA6BBA6BPgLUyGswcov0NEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAECCAYAAADXWsr9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAFk0lEQVR4nO3bP2tedRjG8fu2JfQFNJOKcRChc/A1xMnVzkInu/tGXDoUN8XRQerq4mC6KSItglgXI74AEW6XDvUP5KSek1NzfT7bcwi/XHDy5TxPm/TMFHC1vbT3AGB7QocAQocAQocAQocAQocAQr+A7j7p7u+7+3F3f7D3Hpbr7vvd/Ut3f7P3lj0IfaHuvlZVH1bV21V1q6pud/etfVdxAR9V1cneI/Yi9OXeqqrHM/PDzPxeVZ9U1Ts7b2Khmfmyqn7be8dehL7cy1X10zOvnzy9Bi88oUMAoS/3c1W9+szrV55egxee0Jf7uqre6O7Xu/ugqt6tqs923gSLCH2hmfmjqt6vqi+q6ruq+nRmvt13FUt198dV9VVVvdndT7r7vb03Xab2Z6pw9XmiQwChQwChQwChQwChQwChX1B339l7A88v9f4J/eIif1CukMj7J3QIsMkvzNy8eXOOjo5WP/dFcHZ2VoeHh3vP2NTDhw/3nsB/MDP992vXt/hGR0dHdXp6usXRXILuf/yc8D/nrTsEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEWBR6d5909/fd/bi7P9h6FLCuc0Pv7mtV9WFVvV1Vt6rqdnff2noYsJ4lT/S3qurxzPwwM79X1SdV9c62s4A1LQn95ar66ZnXT55eA/4nVvvHuO6+092n3X16dna21rHACpaE/nNVvfrM61eeXvuLmbk3M8czc3x4eLjWPmAFS0L/uqre6O7Xu/ugqt6tqs+2nQWs6fp5XzAzf3T3+1X1RVVdq6r7M/Pt5suA1ZwbelXVzHxeVZ9vvAXYiN+MgwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwBChwDXtzj00aNHdXJyssXRXIIHDx7sPYHndPfu3X+97okOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAc4Nvbvvd/cv3f3NZQwC1rfkif5RVZ1svAPY0Lmhz8yXVfXbJWwBNuIzOgS4vtZB3X2nqu5UVd24cWOtY4EVrPZEn5l7M3M8M8cHBwdrHQuswFt3CLDkv9c+rqqvqurN7n7S3e9tPwtY07mf0Wfm9mUMAbbjrTsEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoE6JlZ/9Dus6r6cfWDXww3q+rXvUfw3K76/XttZg7/fnGT0K+y7j6dmeO9d/B8Uu+ft+4QQOgQQOgXd2/vAfwnkffPZ3QI4IkOAYQOAYQOAYQOAYQOAf4EWkytDAKHFE8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAECCAYAAADXWsr9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAFlklEQVR4nO3bv4oe9RvG4ecxyR5BtlL5rYUIqRchZxArW1MGIZUH4InYpAh2iqWFYGuzhZtOMUIQfhgbVzwAER6bFPEP7Gyc2Yl7X1f3Dst3b5j9MO+b7PbMFHC1vbL3AGB7QocAQocAQocAQocAQocAQr+A7r7T3d9395Pu/nDvPSzX3Q+7++fu/mbvLXsQ+kLdfa2qPqqqd6rqVlXd7e5b+67iAj6uqjt7j9iL0Jd7u6qezMwPM/NbVX1aVe/uvImFZuarqvp17x17Efpyr1bVj8+9fvrsGrz0hA4BhL7cT1X1+nOvX3t2DV56Ql/u66p6s7vf6O6Dqnqvqj7feRMsIvSFZub3qvqgqr6squ+q6rOZ+XbfVSzV3Z9U1UlVvdXdT7v7/b03Xab2Z6pw9XmiQwChQwChQwChQwChQwChX1B33997Ay8u9f4J/eIif1CukMj7J3QIsMkvzNy8eXOOjo5WP/dlcHZ2VoeHh3vP2NSjR4/2nsC/MDP912vXt/hGR0dHdXp6usXRXILuv/2c8B/nrTsEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEWBR6d9/p7u+7+0l3f7j1KGBd54be3deq6qOqeqeqblXV3e6+tfUwYD1LnuhvV9WTmflhZn6rqk+r6t1tZwFrWhL6q1X143Ovnz67BvxHrPaPcd19v7tPu/v07OxsrWOBFSwJ/aeqev251689u/YnM/NgZo5n5vjw8HCtfcAKloT+dVW92d1vdPdBVb1XVZ9vOwtY0/XzvmBmfu/uD6rqy6q6VlUPZ+bbzZcBqzk39Kqqmfmiqr7YeAuwEb8ZBwGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGub3Ho48eP6/bt21sczSU4OTnZewIv6N69e/943RMdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdApwbenc/7O6fu/ubyxgErG/JE/3jqrqz8Q5gQ+eGPjNfVdWvl7AF2IjP6BDg+loHdff9qrpfVXVwcLDWscAKVnuiz8yDmTmemeMbN26sdSywAm/dIcCS/177pKpOquqt7n7a3e9vPwtY07mf0Wfm7mUMAbbjrTsEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoE6JlZ/9Dus6r6/+oHvxxuVtUve4/ghV31+/e/mTn868VNQr/Kuvt0Zo733sGLSb1/3rpDAKFDAKFf3IO9B/CvRN4/n9EhgCc6BBA6BBA6BBA6BBA6BPgDBMOs1ka2WzoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAECCAYAAADXWsr9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAFlklEQVR4nO3bv4oeZRTH8XPMxivIViquhQjpAovXECtbQ0ohlRfgjdikCHaKpYVga2PhJpVGhCCIsXHFC5DAsUkR/8DOxpmduL/Pp5uH5dkD8373mXf33Z6ZAi63l/YeANie0CGA0CGA0CGA0CGA0CGA0M+hu2929w/d/ai7P9x7Hpbr7nvd/Wt3f7v3LHsQ+kLdfaWqPqqqd6rqelXd6u7r+07FOXxcVTf3HmIvQl/u7ap6NDM/zswfVfVpVb2780wsNDNfVdXve8+xF6Ev90pV/fzM9eOna/DCEzoEEPpyv1TVa89cv/p0DV54Ql/um6p6s7vf6O6Xq+q9qvp855lgEaEvNDNPquqDqvqyqr6vqs9m5rt9p2Kp7v6kqr6uqre6+3F3v7/3TBep/ZsqXH5OdAggdAggdAggdAggdAgg9HPq7jt7z8DzS71/Qj+/yBfKJRJ5/4QOATb5wMy1a9fm6Oho9X1fBKenp3V4eLj3GJu6f//+3iPwH8xM/33tYItvdHR0VCcnJ1tszQXo/sfrhP85j+4QQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQYFHo3X2zu3/o7kfd/eHWQwHrOjP07r5SVR9V1TtVdb2qbnX39a0HA9az5ER/u6oezcyPM/NHVX1aVe9uOxawpiWhv1JVPz9z/fjpGvA/sdov47r7TnefdPfJ6enpWtsCK1gS+i9V9doz168+XfuLmbk7M8czc3x4eLjWfMAKloT+TVW92d1vdPfLVfVeVX2+7VjAmg7O+oKZedLdH1TVl1V1paruzcx3m08GrObM0KuqZuaLqvpi41mAjfhkHAQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQ42GLThw8f1o0bN7bYmgvw4MGDvUfgOd2+fftf153oEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEODM0Lv7Xnf/2t3fXsRAwPqWnOgfV9XNjecANnRm6DPzVVX9fgGzABvxHh0CHKy1UXffqao7VVVXr15da1tgBaud6DNzd2aOZ+b44GC1nx/ACjy6Q4Alf177pKq+rqq3uvtxd7+//VjAms58xp6ZWxcxCLAdj+4QQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQoGdm/U27T6vqp9U3fjFcq6rf9h6C53bZ79/rM3P498VNQr/MuvtkZo73noPnk3r/PLpDAKFDAKGf3929B+A/ibx/3qNDACc6BBA6BBA6BBA6BBA6BPgTbIistZf6FSEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "iter = 0\n",
    "iteration_test = []\n",
    "BMI_grade = []\n",
    "ii = 0\n",
    "sup = \"_SMOTE\"\n",
    "PATH = \"LR_Result\" + sup\n",
    "import os\n",
    "os.makedirs(PATH,exist_ok=True)\n",
    "\n",
    "iter = 0\n",
    "iteration_test = []\n",
    "ii = 0\n",
    "for top_count in [4,5,6,7,8]:\n",
    "    print_list = []\n",
    "    ct = 0\n",
    "    for ii in [1,2]: # sex\n",
    "        data = pd.read_csv(\"DATA/hn2016_all.csv\",encoding='utf-8', low_memory=False)\n",
    "        data2 = pd.read_csv(\"DATA/hn2017_all.csv\",encoding='utf-8', low_memory=False)\n",
    "        data3 = pd.read_csv(\"DATA/hn2018_all.csv\",encoding='utf-8', low_memory=False)\n",
    "        data4 = pd.read_csv(\"DATA/hn2019_all.csv\",encoding='utf-8', low_memory=False)\n",
    "        \n",
    "        gender = data['sex']\n",
    "        gender2 = data2['sex']\n",
    "        gender3 = data3['sex']\n",
    "        gender4 = data4['sex']\n",
    "        \n",
    "        age_list = [[19, 39], [39, 59], [59, 79]]\n",
    "        for age in range(len(age_list)): \n",
    "            \n",
    "            data_copy = data[(data['age']>=age_list[age][0]) & (data['age']<age_list[age][1])].copy()\n",
    "            data2_copy = data2[(data2['age']>=age_list[age][0]) & (data2['age']<age_list[age][1])].copy()\n",
    "            data3_copy = data3[(data3['age']>=age_list[age][0]) & (data3['age']<age_list[age][1])].copy()\n",
    "            data4_copy = data4[(data4['age']>=age_list[age][0]) & (data4['age']<age_list[age][1])].copy()\n",
    "            \n",
    "            sex = [ii]\n",
    "            data_copy = data_copy.loc[gender.isin(sex)]\n",
    "            data2_copy = data2_copy.loc[gender2.isin(sex)]\n",
    "            data3_copy = data3_copy.loc[gender3.isin(sex)]\n",
    "            data4_copy = data4_copy.loc[gender4.isin(sex)]\n",
    "            \n",
    "            Feature_Selection = pd.read_csv('RFC_Feature_Selection/RFC_feature_selection_Binary_OverSampling.csv', index_col = 0)\n",
    "            filtering = Feature_Selection[(Feature_Selection['gender'] == ii) & (Feature_Selection['age'] == str(age_list[age]))]\n",
    "            column_feature = ['HE_BMI'] + list(filtering.index[0:top_count])\n",
    "            \n",
    "            \n",
    "            data_select = data_copy[column_feature].copy()\n",
    "            data_select2 = data2_copy[column_feature].copy()\n",
    "            data_select3 = data3_copy[column_feature].copy()\n",
    "            data_select4 = data4_copy[column_feature].copy()\n",
    "            for i in range(len(column_feature)):\n",
    "                BMI_grade.append([])\n",
    "                ## 숫자로 바꿔주는 코드임.\n",
    "                data_select[column_feature[i]] = pd.to_numeric(data_select[column_feature[i]], errors='coerce').astype(float).round(2)\n",
    "                data_select2[column_feature[i]] = pd.to_numeric(data_select2[column_feature[i]], errors='coerce').astype(float).round(2)\n",
    "                data_select3[column_feature[i]] = pd.to_numeric(data_select3[column_feature[i]], errors='coerce').astype(float).round(2)\n",
    "                data_select4[column_feature[i]] = pd.to_numeric(data_select4[column_feature[i]], errors='coerce').astype(float).round(2)            #print(len(df)) #16000개\n",
    "                \n",
    "\n",
    "            df1 = data_select[column_feature]\n",
    "            df2 = data_select2[column_feature]\n",
    "            df3 = data_select3[column_feature]\n",
    "            df4 = data_select4[column_feature]\n",
    "            \n",
    "            df = pd.concat([df1, df2, df3, df4], ignore_index=True) # 18년 19년 자료 합쳐주는 부분.\n",
    "            df = df.dropna(how = 'any')\n",
    "            df = df.sort_values(by = 'HE_BMI')\n",
    "            for i in range(len(column_feature)):\n",
    "                ### 8,9제거\n",
    "                if column_feature[i] in list999:\n",
    "                    df.drop(df[(df[column_feature[i]] == 888) | (df[column_feature[i]] == 999)].index, inplace = True)\n",
    "                elif column_feature[i] in list88:\n",
    "                    df.drop(df[(df[column_feature[i]] == 88) | (df[column_feature[i]] == 99)].index, inplace = True)\n",
    "                else:\n",
    "                    df.drop(df[(df[column_feature[i]] == 8) | (df[column_feature[i]] == 9)].index, inplace = True)\n",
    "\n",
    "            BMI_tmp = df['HE_BMI']\n",
    "            for k in range(len(df)): #여기서 문제가 생기는구나. 어떡할까\n",
    "                # print(i+cl*(ii-1)+len(age_list)*(age))\n",
    "                if BMI_tmp.iloc[k] < 23:\n",
    "                    BMI_grade[iter].append(0)\n",
    "                elif 23 <= BMI_tmp.iloc[k]:\n",
    "                    BMI_grade[iter].append(1)\n",
    "            tree_data = df.drop(['HE_BMI'],axis = 1)\n",
    "            \n",
    "            \n",
    "            iteration_test.append([iter,ct])\n",
    "            if tree_data.empty == False:\n",
    "                #########################################################\n",
    "                # data normalizaion\n",
    "                min_max_scaler = preprocessing.MinMaxScaler()\n",
    "                x_scaled = min_max_scaler.fit_transform(tree_data)\n",
    "                tree_data = pd.DataFrame(x_scaled,columns=tree_data.columns)\n",
    "                tree_data['BMI_grade'] = BMI_grade[iter]\n",
    "\n",
    "                X = tree_data.iloc[:,:-1]\n",
    "                y = tree_data.iloc[:,-1:]\n",
    "                # y = y.squeeze()\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "\n",
    "                train_ = pd.concat([X_train, y_train], axis=1)\n",
    "                # print(train_)\n",
    "                \n",
    "                cnt_list = train_['BMI_grade'].squeeze()\n",
    "                cnt_list = cnt_list.tolist()\n",
    "                # cnt2 = cnt_list.count(2)\n",
    "                cnt1 = cnt_list.count(1)\n",
    "                cnt0 = cnt_list.count(0)\n",
    "                print(cnt0)\n",
    "                print(cnt1)\n",
    "                # tree_data_1 = y_train.copy()\n",
    "                # print(tree_data_1)\n",
    "\n",
    "                iteration_test[iter].append([cnt0, cnt1])\n",
    "                \n",
    "                # cnt_min = min(cnt0, cnt1, cnt2)\n",
    "                # cnt_max = max(cnt0, cnt1, cnt2)\n",
    "                \n",
    "                # if cnt1 * cnt0 != 0:\n",
    "                #     if cnt1/cnt0 > 1.2:\n",
    "                #         cnt_select = cnt1-cnt0 # 얼마나 차이가 나는지\n",
    "                #         print(cnt_select)\n",
    "                #         local = train_.loc[(train_['BMI_grade']==0)] #0인 갯수가 부족하니까 그것들을 추출\n",
    "                #         idx = local.index.values # 추출한 것의 index\n",
    "                #         select_list = [random.choice(idx) for i in range(cnt_select)] #랜덤으로 추출된 idx들 모음\n",
    "                #         tree_data_2 = train_.loc[select_list]\n",
    "                #         # print(' 0만 추출된 data')\n",
    "                #         # print(tree_data_2)\n",
    "                #         tree_data = pd.concat([train_,tree_data_2], ignore_index=True)\n",
    "                #         # print(tree_data)\n",
    "                        \n",
    "                #         X_train = tree_data.iloc[:,:-1]\n",
    "                #         y_train = tree_data.iloc[:,-1:]\n",
    "\n",
    "                #     elif cnt0/cnt1 > 1.2:\n",
    "                #         cnt_select = cnt0-cnt1\n",
    "                #         print(cnt_select)\n",
    "                #         local = train_.loc[(train_['BMI_grade']==1)]\n",
    "                #         idx = local.index.values\n",
    "                #         select_list = [random.choice(idx) for i in range(cnt_select)]\n",
    "                #         tree_data_2 = train_.loc[select_list]\n",
    "                #         # print(' 1만 추출된 data')\n",
    "                #         # print(tree_data_2)\n",
    "                #         tree_data = pd.concat([train_,tree_data_2], ignore_index=True)\n",
    "                #         # print(tree_data)\n",
    "\n",
    "                        # X_train = tree_data.iloc[:,:-1]\n",
    "                        # y_train = tree_data.iloc[:,-1:]\n",
    "\n",
    "                ###############\n",
    "                ### SMOTE #####\n",
    "                ###############\n",
    "                sm = SMOTE(random_state=12)#, ratio = 1.0)\n",
    "                X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "                #######################\n",
    "                # cnt_list = tree_data['BMI_grade'].tolist()\n",
    "                # cnt1 = cnt_list.count(1)\n",
    "                # cnt0 = cnt_list.count(0)\n",
    "                ########################\n",
    "\n",
    "                cnt_list = y_train['BMI_grade'].squeeze()\n",
    "                cnt_list = cnt_list.tolist()\n",
    "                # cnt2 = cnt_list.count(2)\n",
    "                cnt1 = cnt_list.count(1)\n",
    "                cnt0 = cnt_list.count(0)\n",
    "                print(cnt0)\n",
    "                print(cnt1)\n",
    "                \n",
    "                train_data_size = len(y_train)\n",
    "                test_data_size = len(y_test)\n",
    "                \n",
    "                ##########################################################\n",
    "                \n",
    "                \n",
    "                clf = LogisticRegression(max_iter=1000)\n",
    "                clf.fit(X_train,y_train)\n",
    "                y_pred = clf.predict(X_test)\n",
    "                r_score = recall_score(y_test, y_pred)\n",
    "                p_score = precision_score(y_test, y_pred)\n",
    "                f_score = f1_score(y_test, y_pred)\n",
    "                accuracy = clf.score(X_test,y_test)\n",
    "                TP = perf_measure(np.array(y_test), y_pred)[0]\n",
    "                FP = perf_measure(np.array(y_test), y_pred)[1]\n",
    "                TN = perf_measure(np.array(y_test), y_pred)[2]\n",
    "                FN = perf_measure(np.array(y_test), y_pred)[3]\n",
    "                #print(str(ii) + ' ' + str(age_list[age]) + ' ' + str(i+1) + 'th group')\n",
    "                \n",
    "                print_list.append([])\n",
    "                print_list[ct].append(str(sex))\n",
    "                print_list[ct].append(str(age_list[age]))\n",
    "                # print_list[ct].append(str(print_name[i]) + \"th_group\")\n",
    "                print_list[ct].append(str(column_feature))\n",
    "                print_list[ct].append(str(cnt0))\n",
    "                print_list[ct].append(str(cnt1))\n",
    "                \n",
    "                print_list[ct].append(str(train_data_size))\n",
    "                print_list[ct].append(str(test_data_size))\n",
    "                \n",
    "                print_list[ct].append(TP)\n",
    "                print_list[ct].append(FP)\n",
    "                print_list[ct].append(TN)\n",
    "                print_list[ct].append(FN)\n",
    "                print_list[ct].append(np.round(accuracy,3))\n",
    "                print_list[ct].append(np.round(r_score,3))\n",
    "                print_list[ct].append(np.round(p_score,3))\n",
    "                print_list[ct].append(np.round(f_score,3))\n",
    "                \n",
    "                fpr,tpr, threshold = roc_curve(y_test,clf.predict_proba(X_test)[:, 1])\n",
    "                plt.figure()\n",
    "                plt.plot(fpr,tpr,label = \"roc curve\")\n",
    "                plt.xlabel(\"FPR\")\n",
    "                plt.ylabel(\"TPR\")\n",
    "\n",
    "                plt.legend(loc = 4)\n",
    "                plt.fill_between(fpr,tpr, alpha=0.5)\n",
    "                clf_auc = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "                plt.text(0.65,0.2,\"AUC score: {:.3f}\".format(clf_auc))\n",
    "                plt.title('top ' + str(top_count) + ' ' + str(ii) + ' ' + str(age_list[age]) + ' LR'  + sup + '.png')\n",
    "                plt.savefig(PATH +'/top ' + str(top_count) + ' ' + str(ii) + ' ' + str(age_list[age]) + ' LR' + sup + '.png')\n",
    "                plt.close()\n",
    "                \n",
    "                from sklearn.model_selection import cross_val_predict\n",
    "                from sklearn.metrics import confusion_matrix\n",
    "                y_train_pred = cross_val_predict(clf, X_train, y_train.values.ravel())\n",
    "                conf_mx = confusion_matrix(y_train.values.ravel(), y_train_pred)\n",
    "                plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "                plt.savefig(PATH +\"/Top \" + str(top_count)\n",
    "                            + \" \" + str(age_list[age])\n",
    "                            + \" \" + str(ii) + ' confusion-matrix' + sup + '.png')\n",
    "                \n",
    "                ct += 1\n",
    "                \n",
    "            elif cnt1 * cnt0 == 0:\n",
    "                print('확인해야함!!')\n",
    "                print(column_feature[i])\n",
    "            \n",
    "            iter += 1\n",
    "        \n",
    "        \n",
    "    pl = pd.DataFrame(print_list,\n",
    "                        columns=['gender',\n",
    "                                '<= age <',\n",
    "                                # \"group\",\n",
    "                                \"list\",\n",
    "                                'Number Of 0',\n",
    "                                'Number of 1',\n",
    "                                'Train_data_size',\n",
    "                                'Test_data_size',\n",
    "                                'TP',\n",
    "                                'FP',\n",
    "                                'TN',\n",
    "                                'FN',\n",
    "                                'accuracy score',\n",
    "                                'recall score',\n",
    "                                'precision score',\n",
    "                                'f1 score'])\n",
    "\n",
    "    pl.to_csv(PATH + '/top ' + str(top_count) + ' LR_혈액검사 데이터' + sup + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MULTICLASS, gender = [1,2], age = [[19, 39], [39, 59], [59, 79]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = 0\n",
    "iteration_test = []\n",
    "BMI_grade = []\n",
    "ii = 0\n",
    "sup = \"_OVR_SMOTE_micro_2\"\n",
    "PATH = \"LR_Result\" + sup\n",
    "import os\n",
    "os.makedirs(PATH,exist_ok=True)\n",
    "for top_count in [4,5,6,7,8]:\n",
    "    print_list = []\n",
    "    ct = 0\n",
    "    for ii in [1,2]: # sex\n",
    "        data = pd.read_csv(\"DATA/hn2016_all.csv\",encoding='utf-8', low_memory=False)\n",
    "        data2 = pd.read_csv(\"DATA/hn2017_all.csv\",encoding='utf-8', low_memory=False)\n",
    "        data3 = pd.read_csv(\"DATA/hn2018_all.csv\",encoding='utf-8', low_memory=False)\n",
    "        data4 = pd.read_csv(\"DATA/hn2019_all.csv\",encoding='utf-8', low_memory=False)\n",
    "        \n",
    "        gender = data['sex']\n",
    "        gender2 = data2['sex']\n",
    "        gender3 = data3['sex']\n",
    "        gender4 = data4['sex']\n",
    "        \n",
    "        age_list = [[19, 39], [39, 59], [59, 79]]\n",
    "        # age_list = [[19, 49], [49, 79]]\n",
    "        for age in range(len(age_list)): \n",
    "            \n",
    "            data_copy = data[(data['age']>=age_list[age][0]) & (data['age']<age_list[age][1])].copy()\n",
    "            data2_copy = data2[(data2['age']>=age_list[age][0]) & (data2['age']<age_list[age][1])].copy()\n",
    "            data3_copy = data3[(data3['age']>=age_list[age][0]) & (data3['age']<age_list[age][1])].copy()\n",
    "            data4_copy = data4[(data4['age']>=age_list[age][0]) & (data4['age']<age_list[age][1])].copy()\n",
    "            \n",
    "            sex = [ii]\n",
    "            data_copy = data_copy.loc[gender.isin(sex)]\n",
    "            data2_copy = data2_copy.loc[gender2.isin(sex)]\n",
    "            data3_copy = data3_copy.loc[gender3.isin(sex)]\n",
    "            data4_copy = data4_copy.loc[gender4.isin(sex)]\n",
    "            \n",
    "            Feature_Selection = pd.read_csv('RFC_Feature_Selection/RFC_feature_selection_Multiclass_OverSampling.csv', index_col = 0)\n",
    "            filtering = Feature_Selection[(Feature_Selection['gender'] == ii) & (Feature_Selection['age'] == str(age_list[age]))]\n",
    "            column_feature = ['HE_BMI'] + list(filtering.index[0:top_count])\n",
    "            \n",
    "            \n",
    "            data_select = data_copy[column_feature].copy()\n",
    "            data_select2 = data2_copy[column_feature].copy()\n",
    "            data_select3 = data3_copy[column_feature].copy()\n",
    "            data_select4 = data4_copy[column_feature].copy()\n",
    "            for i in range(len(column_feature)):\n",
    "                BMI_grade.append([])\n",
    "                ## 숫자로 바꿔주는 코드임.\n",
    "                data_select[column_feature[i]] = pd.to_numeric(data_select[column_feature[i]], errors='coerce').astype(float).round(2)\n",
    "                data_select2[column_feature[i]] = pd.to_numeric(data_select2[column_feature[i]], errors='coerce').astype(float).round(2)\n",
    "                data_select3[column_feature[i]] = pd.to_numeric(data_select3[column_feature[i]], errors='coerce').astype(float).round(2)\n",
    "                data_select4[column_feature[i]] = pd.to_numeric(data_select4[column_feature[i]], errors='coerce').astype(float).round(2)            #print(len(df)) #16000개\n",
    "                \n",
    "\n",
    "            df1 = data_select[column_feature]\n",
    "            df2 = data_select2[column_feature]\n",
    "            df3 = data_select3[column_feature]\n",
    "            df4 = data_select4[column_feature]\n",
    "            \n",
    "            df = pd.concat([df1, df2, df3, df4], ignore_index=True) # 18년 19년 자료 합쳐주는 부분.\n",
    "            df = df.dropna(how = 'any')\n",
    "            df = df.sort_values(by = 'HE_BMI')\n",
    "            for i in range(len(column_feature)):\n",
    "                ### 8,9제거\n",
    "                if column_feature[i] in list999:\n",
    "                    df.drop(df[(df[column_feature[i]] == 888) | (df[column_feature[i]] == 999)].index, inplace = True)\n",
    "                elif column_feature[i] in list88:\n",
    "                    df.drop(df[(df[column_feature[i]] == 88) | (df[column_feature[i]] == 99)].index, inplace = True)\n",
    "                else:\n",
    "                    df.drop(df[(df[column_feature[i]] == 8) | (df[column_feature[i]] == 9)].index, inplace = True)\n",
    "\n",
    "            BMI_tmp = df['HE_BMI']\n",
    "            for k in range(len(df)): #여기서 문제가 생기는구나. 어떡할까\n",
    "                # print(i+cl*(ii-1)+len(age_list)*(age))\n",
    "                if BMI_tmp.iloc[k] < 23:\n",
    "                    BMI_grade[iter].append(0)\n",
    "                elif 23 <= BMI_tmp.iloc[k] < 25:\n",
    "                    BMI_grade[iter].append(1)\n",
    "                elif 25 <= BMI_tmp.iloc[k]:\n",
    "                    BMI_grade[iter].append(2)\n",
    "            tree_data = df.drop(['HE_BMI'],axis = 1)\n",
    "            \n",
    "            \n",
    "            iteration_test.append([iter,ct])\n",
    "            if tree_data.empty == False:\n",
    "                #########################################################\n",
    "                # data normalizaion\n",
    "                min_max_scaler = preprocessing.MinMaxScaler()\n",
    "                x_scaled = min_max_scaler.fit_transform(tree_data)\n",
    "                tree_data = pd.DataFrame(x_scaled,columns=tree_data.columns)\n",
    "                tree_data['BMI_grade'] = BMI_grade[iter]\n",
    "\n",
    "                X = tree_data.iloc[:,:-1]\n",
    "                y = tree_data.iloc[:,-1:]\n",
    "                # y = y.squeeze()\n",
    "\n",
    "                # from sklearn.preprocessing import label_binarize\n",
    "                # y = label_binarize(y, classes=[0, 1, 2])\n",
    "                n_classes = 3 #고정\n",
    "                \n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "\n",
    "\n",
    "                cnt_dict = dict(Counter(y_train['BMI_grade']))\n",
    "                cnt0 = cnt_dict[0]\n",
    "                cnt1 = cnt_dict[1]\n",
    "                cnt2 = cnt_dict[2]\n",
    "                print(cnt0, cnt1, cnt2)\n",
    "\n",
    "                # #######################\n",
    "                # ###### MANUALLY #######\n",
    "                # #######################\n",
    "                                \n",
    "                # cnt_max = max(cnt0,cnt1,cnt2)\n",
    "                # train_ = pd.concat([X_train, y_train], axis=1)\n",
    "                \n",
    "                # n_resampl_0 = cnt_max - cnt0\n",
    "                # if n_resampl_0 != 0:\n",
    "                #     local = train_.loc[(train_['BMI_grade']==0)] #0인 갯수가 부족하니까 그것들을 추출\n",
    "                #     idx = local.index.values # 추출한 것의 index\n",
    "                #     select_list = [random.choice(idx) for i in range(n_resampl_0)] #랜덤으로 추출된 idx들 모음\n",
    "                #     tree_data_2 = train_.loc[select_list]\n",
    "                #     train_ = pd.concat([train_,tree_data_2], ignore_index=True)\n",
    "                \n",
    "                # n_resampl_1 = cnt_max - cnt1\n",
    "                # if n_resampl_1 != 0:\n",
    "                #     local = train_.loc[(train_['BMI_grade']==1)]\n",
    "                #     idx = local.index.values # 추출한 것의 index\n",
    "                #     select_list = [random.choice(idx) for i in range(n_resampl_1)] #랜덤으로 추출된 idx들 모음\n",
    "                #     tree_data_2 = train_.loc[select_list]\n",
    "                #     train_ = pd.concat([train_,tree_data_2], ignore_index=True)\n",
    "                \n",
    "                # n_resampl_2 = cnt_max - cnt2\n",
    "                # if n_resampl_2 != 0:\n",
    "                #     local = train_.loc[(train_['BMI_grade']==2)]\n",
    "                #     idx = local.index.values # 추출한 것의 index\n",
    "                #     select_list = [random.choice(idx) for i in range(n_resampl_2)] #랜덤으로 추출된 idx들 모음\n",
    "                #     tree_data_2 = train_.loc[select_list]\n",
    "                #     train_ = pd.concat([train_,tree_data_2], ignore_index=True)\n",
    "                \n",
    "                # X_train = train_.iloc[:,:-1]\n",
    "                # y_train = train_.iloc[:,-1:]\n",
    "\n",
    "                ###############\n",
    "                ### SMOTE #####\n",
    "                ###############\n",
    "                sm = SMOTE(random_state=12)#, ratio = 1.0)\n",
    "                X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "                \n",
    "                cnt_dict = dict(Counter(y_train['BMI_grade']))\n",
    "                cnt0 = cnt_dict[0]\n",
    "                cnt1 = cnt_dict[1]\n",
    "                cnt2 = cnt_dict[2]\n",
    "                print('after augmentation')\n",
    "                print(cnt0, cnt1, cnt2)\n",
    "                print('------------------')\n",
    "                ##########################################################\n",
    "                clf = LogisticRegression(multi_class='ovr')\n",
    "                parameters = { \"penalty\" : [\"l2\", \"l1\"], \"C\" : [0.01, 0.1, 1, 5, 10] }\n",
    "                ##################GRID SEARCH CV\n",
    "                # parameters = {'gamma':[0.01, 0.1,0.5,1,5,10,30,50],\n",
    "                #             'C':[0.01, 0.1,0.5,1,5,10,30,50]}\n",
    "                grid_dtree = GridSearchCV(clf,param_grid=parameters,cv=3,refit=True)\n",
    "                grid_dtree.fit(X_train,y_train)\n",
    "\n",
    "                print('GridSearchCV 최적 파라미터:', grid_dtree.best_params_)\n",
    "                print('GridSearchCV 최고 정확도: {0:.4f}'.format(grid_dtree.best_score_))\n",
    "\n",
    "                fig = plt.figure(2*i)\n",
    "                # results = pd.DataFrame(grid_dtree.cv_results_)\n",
    "                # scores = np.array(results.mean_test_score).reshape(8, 8)\n",
    "                # /mg.tools.heatmap(scores, xlabel='gamma', xticklabels=parameters['gamma'],ylabel='C', yticklabels=parameters['C'], cmap=\"viridis\")\n",
    "                best_param = list(grid_dtree.best_params_.values())\n",
    "                # plt.title(grid_dtree.best_params_.items())\n",
    "                # plt.savefig(PATH + '/top ' + str(top_count) + ' ' + str(ii) + ' ' + str(age_list[age]) + ' ' + str(i+1) + \"_\" + 'Heatmap' + \".png\", dpi=300)\n",
    "                # plt.close()\n",
    "                # plt.show()\n",
    "\n",
    "                clf = LogisticRegression(penalty = best_param[1], C = best_param[0], max_iter=1000, multi_class='ovr', solver='lbfgs')\n",
    "                clf.fit(X_train,y_train.values.ravel())\n",
    "                y_pred = clf.predict(X_test) \n",
    "\n",
    "                r_score = recall_score(y_test, y_pred, average = 'micro')\n",
    "                p_score = precision_score(y_test, y_pred, average = 'micro')\n",
    "                f_score = f1_score(y_test, y_pred, average = 'micro')\n",
    "                accuracy = clf.score(X_test,y_test)#, average = None)\n",
    "                # TP = perf_measure(np.array(y_test), y_pred)[0]\n",
    "                # FP = perf_measure(np.array(y_test), y_pred)[1]\n",
    "                # TN = perf_measure(np.array(y_test), y_pred)[2]\n",
    "                # FN = perf_measure(np.array(y_test), y_pred)[3]\n",
    "                \n",
    "                print_list.append([])\n",
    "                print_list[ct].append(str(sex))\n",
    "                print_list[ct].append(str(age_list[age]))\n",
    "                print_list[ct].append(str(column_feature))\n",
    "                print_list[ct].append(str(cnt0))\n",
    "                print_list[ct].append(str(cnt1))\n",
    "                print_list[ct].append(str(cnt2))\n",
    "                \n",
    "                print_list[ct].append(np.round(accuracy,3))\n",
    "                print_list[ct].append(np.round(r_score,3))\n",
    "                print_list[ct].append(np.round(p_score,3))\n",
    "                print_list[ct].append(np.round(f_score,3))\n",
    "                \n",
    "\n",
    "                # Compute ROC curve and ROC area for each class\n",
    "                fpr = dict()\n",
    "                tpr = dict()\n",
    "                roc_auc = dict()\n",
    "                \n",
    "                y_test = label_binarize(y_test, classes=[0, 1, 2]) # SVC input이 one hot incoding으로 안들어감.\n",
    "                \n",
    "                for i in range(n_classes):\n",
    "                    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], clf.predict_proba(X_test)[:, 1])\n",
    "                    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "                \n",
    "                # Compute micro-average ROC curve and ROC area\n",
    "                fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), clf.predict_proba(X_test).ravel())\n",
    "                roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "                lw = 2\n",
    "                \n",
    "                # First aggregate all false positive rates\n",
    "                all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "                # Then interpolate all ROC curves at this points\n",
    "                mean_tpr = np.zeros_like(all_fpr)\n",
    "                for i in range(n_classes):\n",
    "                    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "                # Finally average it and compute AUC\n",
    "                mean_tpr /= n_classes\n",
    "\n",
    "                fpr[\"macro\"] = all_fpr\n",
    "                tpr[\"macro\"] = mean_tpr\n",
    "                roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "                # Plot all ROC curves\n",
    "                plt.figure(figsize=(9,9))\n",
    "                plt.plot(\n",
    "                    fpr[\"micro\"],\n",
    "                    tpr[\"micro\"],\n",
    "                    label=\"micro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"micro\"]),\n",
    "                    color=\"deeppink\",\n",
    "                    linestyle=\":\",\n",
    "                    linewidth=4,\n",
    "                )\n",
    "\n",
    "                plt.plot(\n",
    "                    fpr[\"macro\"],\n",
    "                    tpr[\"macro\"],\n",
    "                    label=\"macro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"macro\"]),\n",
    "                    color=\"navy\",\n",
    "                    linestyle=\":\",\n",
    "                    linewidth=4,\n",
    "                )\n",
    "\n",
    "                colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\"])\n",
    "                for i, color in zip(range(n_classes), colors):\n",
    "                    plt.plot(\n",
    "                        fpr[i],\n",
    "                        tpr[i],\n",
    "                        color=color,\n",
    "                        lw=lw,\n",
    "                        label=\"ROC curve of class {0} (area = {1:0.2f})\".format(i, roc_auc[i]),\n",
    "                    )\n",
    "\n",
    "                plt.plot([0, 1], [0, 1], \"k--\", lw=lw)\n",
    "                plt.xlim([0.0, 1.0])\n",
    "                plt.ylim([0.0, 1.05])\n",
    "                plt.xlabel(\"False Positive Rate\", fontsize=20)\n",
    "                plt.ylabel(\"True Positive Rate\", fontsize=20)\n",
    "                plt.title(\"Top \" + str(top_count)\n",
    "                            + \" \" + str(age_list[age])\n",
    "                            + \" \" + str(ii) + ' Multiclass ROC', fontsize=20)\n",
    "                plt.legend(loc=\"lower right\", fontsize=15)\n",
    "                plt.savefig(PATH +\"/Top \" + str(top_count)\n",
    "                            + \" \" + str(age_list[age])\n",
    "                            + \" \" + str(ii) + ' ROC-CURVE' + sup + '.png')\n",
    "                plt.show()\n",
    "                from sklearn.model_selection import cross_val_predict\n",
    "                from sklearn.metrics import confusion_matrix\n",
    "                y_train_pred = cross_val_predict(clf, X_train, y_train.values.ravel())\n",
    "                conf_mx = confusion_matrix(y_train.values.ravel(), y_train_pred)\n",
    "                plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "                plt.savefig(PATH +\"/Top \" + str(top_count)\n",
    "                            + \" \" + str(age_list[age])\n",
    "                            + \" \" + str(ii) + ' confusion-matrix' + sup + '.png')\n",
    "                y_prob = clf.predict_proba(X_test).ravel()\n",
    "                macro_roc_auc_ovo = roc_auc_score(y_test.ravel(), y_prob, multi_class=\"ovo\", average=\"macro\")\n",
    "                weighted_roc_auc_ovo = roc_auc_score(\n",
    "                    y_test.ravel(), y_prob, multi_class=\"ovo\", average=\"weighted\"\n",
    "                )\n",
    "                micro_roc_auc_ovo = roc_auc_score(\n",
    "                    y_test.ravel(), y_prob, multi_class=\"ovo\", average=\"micro\"\n",
    "                )\n",
    "                macro_roc_auc_ovr = roc_auc_score(y_test.ravel(), y_prob, multi_class=\"ovr\", average=\"macro\")\n",
    "                weighted_roc_auc_ovr = roc_auc_score(\n",
    "                    y_test.ravel(), y_prob, multi_class=\"ovr\", average=\"weighted\"\n",
    "                )\n",
    "                micro_roc_auc_ovr = roc_auc_score(\n",
    "                    y_test.ravel(), y_prob, multi_class=\"ovr\", average=\"micro\"\n",
    "                )\n",
    "                print(\n",
    "                    \"One-vs-One ROC AUC scores:\\n{:.6f} (macro),\\n{:.6f} \"\n",
    "                    \"(weighted by prevalence)\".format(macro_roc_auc_ovo, weighted_roc_auc_ovo)\n",
    "                )\n",
    "                print(\n",
    "                    \"One-vs-Rest ROC AUC scores:\\n{:.6f} (macro),\\n{:.6f} \"\n",
    "                    \"(weighted by prevalence)\".format(macro_roc_auc_ovr, weighted_roc_auc_ovr)\n",
    "                )\n",
    "                \n",
    "                print_list[ct].append(np.round(macro_roc_auc_ovo,3))\n",
    "                print_list[ct].append(np.round(micro_roc_auc_ovo,3))\n",
    "                print_list[ct].append(np.round(weighted_roc_auc_ovo,3))\n",
    "                print_list[ct].append(np.round(macro_roc_auc_ovr,3))\n",
    "                print_list[ct].append(np.round(micro_roc_auc_ovo,3))\n",
    "                print_list[ct].append(np.round(weighted_roc_auc_ovr,3))\n",
    "                \n",
    "                ct += 1\n",
    "                \n",
    "            iter += 1\n",
    "            \n",
    "            \n",
    "    pl = pd.DataFrame(print_list,\n",
    "                        columns=['gender',\n",
    "                                '<= age <',\n",
    "                                # \"group\",\n",
    "                                \"list\",\n",
    "                                'Number Of 0',\n",
    "                                'Number of 1',\n",
    "                                'Number of 2',\n",
    "                                'accuracy score',\n",
    "                                'recall score',\n",
    "                                'precision score',\n",
    "                                'f1 score',\n",
    "                                'OVO AUC macro',\n",
    "                                'OVO AUC micro',\n",
    "                                'OVO AUC weighted',\n",
    "                                'OVR AUC macro',\n",
    "                                'OVR AUC micro',\n",
    "                                'OVR AUC weighted'])\n",
    "\n",
    "    pl.to_csv(PATH + '/top ' + str(top_count) + ' LR_혈액검사 데이터' + sup + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiclass gender = [1,2], age = [[19, 49], [49, 79]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = 0\n",
    "iteration_test = []\n",
    "BMI_grade = []\n",
    "ii = 0\n",
    "sup = \"_OVR_SMOTE_micro\"\n",
    "PATH = \"LR_Result_194979\" + sup\n",
    "import os\n",
    "os.makedirs(PATH,exist_ok=True)\n",
    "for top_count in [4,5,6,7,8]:\n",
    "    print_list = []\n",
    "    ct = 0\n",
    "    for ii in [1,2]: # sex\n",
    "        data = pd.read_csv(\"DATA/hn2016_all.csv\",encoding='utf-8', low_memory=False)\n",
    "        data2 = pd.read_csv(\"DATA/hn2017_all.csv\",encoding='utf-8', low_memory=False)\n",
    "        data3 = pd.read_csv(\"DATA/hn2018_all.csv\",encoding='utf-8', low_memory=False)\n",
    "        data4 = pd.read_csv(\"DATA/hn2019_all.csv\",encoding='utf-8', low_memory=False)\n",
    "        \n",
    "        gender = data['sex']\n",
    "        gender2 = data2['sex']\n",
    "        gender3 = data3['sex']\n",
    "        gender4 = data4['sex']\n",
    "        \n",
    "        age_list = [[19, 49], [49, 79]]\n",
    "        for age in range(len(age_list)): \n",
    "            \n",
    "            data_copy = data[(data['age']>=age_list[age][0]) & (data['age']<age_list[age][1])].copy()\n",
    "            data2_copy = data2[(data2['age']>=age_list[age][0]) & (data2['age']<age_list[age][1])].copy()\n",
    "            data3_copy = data3[(data3['age']>=age_list[age][0]) & (data3['age']<age_list[age][1])].copy()\n",
    "            data4_copy = data4[(data4['age']>=age_list[age][0]) & (data4['age']<age_list[age][1])].copy()\n",
    "            \n",
    "            sex = [ii]\n",
    "            data_copy = data_copy.loc[gender.isin(sex)]\n",
    "            data2_copy = data2_copy.loc[gender2.isin(sex)]\n",
    "            data3_copy = data3_copy.loc[gender3.isin(sex)]\n",
    "            data4_copy = data4_copy.loc[gender4.isin(sex)]\n",
    "            \n",
    "            Feature_Selection = pd.read_csv('RFC_Feature_Selection/RFC_feature_selection_Multiclass_OverSampling_194979.csv', index_col = 0)\n",
    "            filtering = Feature_Selection[(Feature_Selection['gender'] == ii) & (Feature_Selection['age'] == str(age_list[age]))]\n",
    "            column_feature = ['HE_BMI'] + list(filtering.index[0:top_count])\n",
    "            \n",
    "            \n",
    "            data_select = data_copy[column_feature].copy()\n",
    "            data_select2 = data2_copy[column_feature].copy()\n",
    "            data_select3 = data3_copy[column_feature].copy()\n",
    "            data_select4 = data4_copy[column_feature].copy()\n",
    "            for i in range(len(column_feature)):\n",
    "                BMI_grade.append([])\n",
    "                ## 숫자로 바꿔주는 코드임.\n",
    "                data_select[column_feature[i]] = pd.to_numeric(data_select[column_feature[i]], errors='coerce').astype(float).round(2)\n",
    "                data_select2[column_feature[i]] = pd.to_numeric(data_select2[column_feature[i]], errors='coerce').astype(float).round(2)\n",
    "                data_select3[column_feature[i]] = pd.to_numeric(data_select3[column_feature[i]], errors='coerce').astype(float).round(2)\n",
    "                data_select4[column_feature[i]] = pd.to_numeric(data_select4[column_feature[i]], errors='coerce').astype(float).round(2)            #print(len(df)) #16000개\n",
    "                \n",
    "\n",
    "            df1 = data_select[column_feature]\n",
    "            df2 = data_select2[column_feature]\n",
    "            df3 = data_select3[column_feature]\n",
    "            df4 = data_select4[column_feature]\n",
    "            \n",
    "            df = pd.concat([df1, df2, df3, df4], ignore_index=True) # 18년 19년 자료 합쳐주는 부분.\n",
    "            df = df.dropna(how = 'any')\n",
    "            df = df.sort_values(by = 'HE_BMI')\n",
    "            for i in range(len(column_feature)):\n",
    "                ### 8,9제거\n",
    "                if column_feature[i] in list999:\n",
    "                    df.drop(df[(df[column_feature[i]] == 888) | (df[column_feature[i]] == 999)].index, inplace = True)\n",
    "                elif column_feature[i] in list88:\n",
    "                    df.drop(df[(df[column_feature[i]] == 88) | (df[column_feature[i]] == 99)].index, inplace = True)\n",
    "                else:\n",
    "                    df.drop(df[(df[column_feature[i]] == 8) | (df[column_feature[i]] == 9)].index, inplace = True)\n",
    "\n",
    "            BMI_tmp = df['HE_BMI']\n",
    "            for k in range(len(df)): #여기서 문제가 생기는구나. 어떡할까\n",
    "                # print(i+cl*(ii-1)+len(age_list)*(age))\n",
    "                if BMI_tmp.iloc[k] < 23:\n",
    "                    BMI_grade[iter].append(0)\n",
    "                elif 23 <= BMI_tmp.iloc[k] < 25:\n",
    "                    BMI_grade[iter].append(1)\n",
    "                elif 25 <= BMI_tmp.iloc[k]:\n",
    "                    BMI_grade[iter].append(2)\n",
    "            tree_data = df.drop(['HE_BMI'],axis = 1)\n",
    "            \n",
    "            \n",
    "            iteration_test.append([iter,ct])\n",
    "            if tree_data.empty == False:\n",
    "                #########################################################\n",
    "                # data normalizaion\n",
    "                min_max_scaler = preprocessing.MinMaxScaler()\n",
    "                x_scaled = min_max_scaler.fit_transform(tree_data)\n",
    "                tree_data = pd.DataFrame(x_scaled,columns=tree_data.columns)\n",
    "                tree_data['BMI_grade'] = BMI_grade[iter]\n",
    "\n",
    "                X = tree_data.iloc[:,:-1]\n",
    "                y = tree_data.iloc[:,-1:]\n",
    "                # y = y.squeeze()\n",
    "\n",
    "                # from sklearn.preprocessing import label_binarize\n",
    "                # y = label_binarize(y, classes=[0, 1, 2])\n",
    "                n_classes = 3 #고정\n",
    "                \n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "\n",
    "\n",
    "                cnt_dict = dict(Counter(y_train['BMI_grade']))\n",
    "                cnt0 = cnt_dict[0]\n",
    "                cnt1 = cnt_dict[1]\n",
    "                cnt2 = cnt_dict[2]\n",
    "                print(cnt0, cnt1, cnt2)\n",
    "\n",
    "                # #######################\n",
    "                # ###### MANUALLY #######\n",
    "                # #######################\n",
    "                                \n",
    "                # cnt_max = max(cnt0,cnt1,cnt2)\n",
    "                # train_ = pd.concat([X_train, y_train], axis=1)\n",
    "                \n",
    "                # n_resampl_0 = cnt_max - cnt0\n",
    "                # if n_resampl_0 != 0:\n",
    "                #     local = train_.loc[(train_['BMI_grade']==0)] #0인 갯수가 부족하니까 그것들을 추출\n",
    "                #     idx = local.index.values # 추출한 것의 index\n",
    "                #     select_list = [random.choice(idx) for i in range(n_resampl_0)] #랜덤으로 추출된 idx들 모음\n",
    "                #     tree_data_2 = train_.loc[select_list]\n",
    "                #     train_ = pd.concat([train_,tree_data_2], ignore_index=True)\n",
    "                \n",
    "                # n_resampl_1 = cnt_max - cnt1\n",
    "                # if n_resampl_1 != 0:\n",
    "                #     local = train_.loc[(train_['BMI_grade']==1)]\n",
    "                #     idx = local.index.values # 추출한 것의 index\n",
    "                #     select_list = [random.choice(idx) for i in range(n_resampl_1)] #랜덤으로 추출된 idx들 모음\n",
    "                #     tree_data_2 = train_.loc[select_list]\n",
    "                #     train_ = pd.concat([train_,tree_data_2], ignore_index=True)\n",
    "                \n",
    "                # n_resampl_2 = cnt_max - cnt2\n",
    "                # if n_resampl_2 != 0:\n",
    "                #     local = train_.loc[(train_['BMI_grade']==2)]\n",
    "                #     idx = local.index.values # 추출한 것의 index\n",
    "                #     select_list = [random.choice(idx) for i in range(n_resampl_2)] #랜덤으로 추출된 idx들 모음\n",
    "                #     tree_data_2 = train_.loc[select_list]\n",
    "                #     train_ = pd.concat([train_,tree_data_2], ignore_index=True)\n",
    "                \n",
    "                # X_train = train_.iloc[:,:-1]\n",
    "                # y_train = train_.iloc[:,-1:]\n",
    "\n",
    "                ###############\n",
    "                ### SMOTE #####\n",
    "                ###############\n",
    "                sm = SMOTE(random_state=12)#, ratio = 1.0)\n",
    "                X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "                \n",
    "                cnt_dict = dict(Counter(y_train['BMI_grade']))\n",
    "                cnt0 = cnt_dict[0]\n",
    "                cnt1 = cnt_dict[1]\n",
    "                cnt2 = cnt_dict[2]\n",
    "                print('after augmentation')\n",
    "                print(cnt0, cnt1, cnt2)\n",
    "                print('------------------')\n",
    "                ##########################################################\n",
    "                clf = LogisticRegression(multi_class='ovr')\n",
    "                parameters = { \"penalty\" : [\"l2\", \"l1\"], \"C\" : [0.01, 0.1, 1, 5, 10] }\n",
    "                ##################GRID SEARCH CV\n",
    "                # parameters = {'gamma':[0.01, 0.1,0.5,1,5,10,30,50],\n",
    "                #             'C':[0.01, 0.1,0.5,1,5,10,30,50]}\n",
    "                grid_dtree = GridSearchCV(clf,param_grid=parameters,cv=3,refit=True)\n",
    "                grid_dtree.fit(X_train,y_train)\n",
    "\n",
    "                print('GridSearchCV 최적 파라미터:', grid_dtree.best_params_)\n",
    "                print('GridSearchCV 최고 정확도: {0:.4f}'.format(grid_dtree.best_score_))\n",
    "\n",
    "                fig = plt.figure(2*i)\n",
    "                # results = pd.DataFrame(grid_dtree.cv_results_)\n",
    "                # scores = np.array(results.mean_test_score).reshape(8, 8)\n",
    "                # /mg.tools.heatmap(scores, xlabel='gamma', xticklabels=parameters['gamma'],ylabel='C', yticklabels=parameters['C'], cmap=\"viridis\")\n",
    "                best_param = list(grid_dtree.best_params_.values())\n",
    "                # plt.title(grid_dtree.best_params_.items())\n",
    "                # plt.savefig(PATH + '/top ' + str(top_count) + ' ' + str(ii) + ' ' + str(age_list[age]) + ' ' + str(i+1) + \"_\" + 'Heatmap' + \".png\", dpi=300)\n",
    "                # plt.close()\n",
    "                # plt.show()\n",
    "\n",
    "                clf = LogisticRegression(penalty = best_param[1], C = best_param[0], max_iter=1000, multi_class='ovr', solver='lbfgs')\n",
    "                clf.fit(X_train,y_train.values.ravel())\n",
    "                y_pred = clf.predict(X_test) \n",
    "\n",
    "                r_score = recall_score(y_test, y_pred, average = 'micro')\n",
    "                p_score = precision_score(y_test, y_pred, average = 'micro')\n",
    "                f_score = f1_score(y_test, y_pred, average = 'micro')\n",
    "                accuracy = clf.score(X_test,y_test)#, average = None)\n",
    "                # TP = perf_measure(np.array(y_test), y_pred)[0]\n",
    "                # FP = perf_measure(np.array(y_test), y_pred)[1]\n",
    "                # TN = perf_measure(np.array(y_test), y_pred)[2]\n",
    "                # FN = perf_measure(np.array(y_test), y_pred)[3]\n",
    "                \n",
    "                print_list.append([])\n",
    "                print_list[ct].append(str(sex))\n",
    "                print_list[ct].append(str(age_list[age]))\n",
    "                print_list[ct].append(str(column_feature))\n",
    "                print_list[ct].append(str(cnt0))\n",
    "                print_list[ct].append(str(cnt1))\n",
    "                print_list[ct].append(str(cnt2))\n",
    "                \n",
    "                print_list[ct].append(np.round(accuracy,3))\n",
    "                print_list[ct].append(np.round(r_score,3))\n",
    "                print_list[ct].append(np.round(p_score,3))\n",
    "                print_list[ct].append(np.round(f_score,3))\n",
    "                \n",
    "\n",
    "                # Compute ROC curve and ROC area for each class\n",
    "                fpr = dict()\n",
    "                tpr = dict()\n",
    "                roc_auc = dict()\n",
    "                \n",
    "                y_test = label_binarize(y_test, classes=[0, 1, 2]) # SVC input이 one hot incoding으로 안들어감.\n",
    "                \n",
    "                for i in range(n_classes):\n",
    "                    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], clf.predict_proba(X_test)[:, 1])\n",
    "                    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "                \n",
    "                # Compute micro-average ROC curve and ROC area\n",
    "                fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), clf.predict_proba(X_test).ravel())\n",
    "                roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "                lw = 2\n",
    "                \n",
    "                # First aggregate all false positive rates\n",
    "                all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "                # Then interpolate all ROC curves at this points\n",
    "                mean_tpr = np.zeros_like(all_fpr)\n",
    "                for i in range(n_classes):\n",
    "                    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "                # Finally average it and compute AUC\n",
    "                mean_tpr /= n_classes\n",
    "\n",
    "                fpr[\"macro\"] = all_fpr\n",
    "                tpr[\"macro\"] = mean_tpr\n",
    "                roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "                # Plot all ROC curves\n",
    "                plt.figure(figsize=(9,9))\n",
    "                plt.plot(\n",
    "                    fpr[\"micro\"],\n",
    "                    tpr[\"micro\"],\n",
    "                    label=\"micro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"micro\"]),\n",
    "                    color=\"deeppink\",\n",
    "                    linestyle=\":\",\n",
    "                    linewidth=4,\n",
    "                )\n",
    "\n",
    "                plt.plot(\n",
    "                    fpr[\"macro\"],\n",
    "                    tpr[\"macro\"],\n",
    "                    label=\"macro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"macro\"]),\n",
    "                    color=\"navy\",\n",
    "                    linestyle=\":\",\n",
    "                    linewidth=4,\n",
    "                )\n",
    "\n",
    "                colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\"])\n",
    "                for i, color in zip(range(n_classes), colors):\n",
    "                    plt.plot(\n",
    "                        fpr[i],\n",
    "                        tpr[i],\n",
    "                        color=color,\n",
    "                        lw=lw,\n",
    "                        label=\"ROC curve of class {0} (area = {1:0.2f})\".format(i, roc_auc[i]),\n",
    "                    )\n",
    "\n",
    "                plt.plot([0, 1], [0, 1], \"k--\", lw=lw)\n",
    "                plt.xlim([0.0, 1.0])\n",
    "                plt.ylim([0.0, 1.05])\n",
    "                plt.xlabel(\"False Positive Rate\", fontsize=20)\n",
    "                plt.ylabel(\"True Positive Rate\", fontsize=20)\n",
    "                plt.title(\"Top \" + str(top_count)\n",
    "                            + \" \" + str(age_list[age])\n",
    "                            + \" \" + str(ii) + ' Multiclass ROC', fontsize=20)\n",
    "                plt.legend(loc=\"lower right\", fontsize=15)\n",
    "                plt.savefig(PATH +\"/Top \" + str(top_count)\n",
    "                            + \" \" + str(age_list[age])\n",
    "                            + \" \" + str(ii) + ' ROC-CURVE' + sup + '.png')\n",
    "                plt.show()\n",
    "                from sklearn.model_selection import cross_val_predict\n",
    "                from sklearn.metrics import confusion_matrix\n",
    "                y_train_pred = cross_val_predict(clf, X_train, y_train.values.ravel())\n",
    "                conf_mx = confusion_matrix(y_train.values.ravel(), y_train_pred)\n",
    "                plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "                plt.savefig(PATH +\"/Top \" + str(top_count)\n",
    "                            + \" \" + str(age_list[age])\n",
    "                            + \" \" + str(ii) + ' confusion-matrix' + sup + '.png')\n",
    "                y_prob = clf.predict_proba(X_test).ravel()\n",
    "                macro_roc_auc_ovo = roc_auc_score(y_test.ravel(), y_prob, multi_class=\"ovo\", average=\"macro\")\n",
    "                weighted_roc_auc_ovo = roc_auc_score(\n",
    "                    y_test.ravel(), y_prob, multi_class=\"ovo\", average=\"weighted\"\n",
    "                )\n",
    "                micro_roc_auc_ovo = roc_auc_score(\n",
    "                    y_test.ravel(), y_prob, multi_class=\"ovo\", average=\"micro\"\n",
    "                )\n",
    "                macro_roc_auc_ovr = roc_auc_score(y_test.ravel(), y_prob, multi_class=\"ovr\", average=\"macro\")\n",
    "                weighted_roc_auc_ovr = roc_auc_score(\n",
    "                    y_test.ravel(), y_prob, multi_class=\"ovr\", average=\"weighted\"\n",
    "                )\n",
    "                micro_roc_auc_ovr = roc_auc_score(\n",
    "                    y_test.ravel(), y_prob, multi_class=\"ovr\", average=\"micro\"\n",
    "                )\n",
    "                print(\n",
    "                    \"One-vs-One ROC AUC scores:\\n{:.6f} (macro),\\n{:.6f} \"\n",
    "                    \"(weighted by prevalence)\".format(macro_roc_auc_ovo, weighted_roc_auc_ovo)\n",
    "                )\n",
    "                print(\n",
    "                    \"One-vs-Rest ROC AUC scores:\\n{:.6f} (macro),\\n{:.6f} \"\n",
    "                    \"(weighted by prevalence)\".format(macro_roc_auc_ovr, weighted_roc_auc_ovr)\n",
    "                )\n",
    "                \n",
    "                print_list[ct].append(np.round(macro_roc_auc_ovo,3))\n",
    "                print_list[ct].append(np.round(micro_roc_auc_ovo,3))\n",
    "                print_list[ct].append(np.round(weighted_roc_auc_ovo,3))\n",
    "                print_list[ct].append(np.round(macro_roc_auc_ovr,3))\n",
    "                print_list[ct].append(np.round(micro_roc_auc_ovo,3))\n",
    "                print_list[ct].append(np.round(weighted_roc_auc_ovr,3))\n",
    "                \n",
    "                ct += 1\n",
    "                \n",
    "            iter += 1\n",
    "            \n",
    "            \n",
    "    pl = pd.DataFrame(print_list,\n",
    "                        columns=['gender',\n",
    "                                '<= age <',\n",
    "                                # \"group\",\n",
    "                                \"list\",\n",
    "                                'Number Of 0',\n",
    "                                'Number of 1',\n",
    "                                'Number of 2',\n",
    "                                'accuracy score',\n",
    "                                'recall score',\n",
    "                                'precision score',\n",
    "                                'f1 score',\n",
    "                                'OVO AUC macro',\n",
    "                                'OVO AUC micro',\n",
    "                                'OVO AUC weighted',\n",
    "                                'OVR AUC macro',\n",
    "                                'OVR AUC micro',\n",
    "                                'OVR AUC weighted'])\n",
    "\n",
    "    pl.to_csv(PATH + '/top ' + str(top_count) + ' LR_혈액검사 데이터' + sup + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiclass no gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = 0\n",
    "iteration_test = []\n",
    "BMI_grade = []\n",
    "ii = 0\n",
    "sup = \"_OVR_SMOTE_micro_2\"\n",
    "PATH = \"LR_Result_No_gender\" + sup\n",
    "import os\n",
    "os.makedirs(PATH,exist_ok=True)\n",
    "for top_count in [4,5,6,7,8]:\n",
    "    print_list = []\n",
    "    ct = 0\n",
    "    for ii in [1]:#,2]: # sex\n",
    "        data = pd.read_csv(\"DATA/hn2016_all.csv\",encoding='utf-8', low_memory=False)\n",
    "        data2 = pd.read_csv(\"DATA/hn2017_all.csv\",encoding='utf-8', low_memory=False)\n",
    "        data3 = pd.read_csv(\"DATA/hn2018_all.csv\",encoding='utf-8', low_memory=False)\n",
    "        data4 = pd.read_csv(\"DATA/hn2019_all.csv\",encoding='utf-8', low_memory=False)\n",
    "        \n",
    "        gender = data['sex']\n",
    "        gender2 = data2['sex']\n",
    "        gender3 = data3['sex']\n",
    "        gender4 = data4['sex']\n",
    "        \n",
    "        age_list = [[19, 39], [39, 59], [59, 79]]\n",
    "        # age_list = [[19, 49], [49, 79]]\n",
    "        for age in range(len(age_list)): \n",
    "            \n",
    "            data_copy = data[(data['age']>=age_list[age][0]) & (data['age']<age_list[age][1])].copy()\n",
    "            data2_copy = data2[(data2['age']>=age_list[age][0]) & (data2['age']<age_list[age][1])].copy()\n",
    "            data3_copy = data3[(data3['age']>=age_list[age][0]) & (data3['age']<age_list[age][1])].copy()\n",
    "            data4_copy = data4[(data4['age']>=age_list[age][0]) & (data4['age']<age_list[age][1])].copy()\n",
    "            \n",
    "            # sex = [ii]\n",
    "            # data_copy = data_copy.loc[gender.isin(sex)]\n",
    "            # data2_copy = data2_copy.loc[gender2.isin(sex)]\n",
    "            # data3_copy = data3_copy.loc[gender3.isin(sex)]\n",
    "            # data4_copy = data4_copy.loc[gender4.isin(sex)]\n",
    "            \n",
    "            Feature_Selection = pd.read_csv('RFC_Feature_Selection/RFC_feature_selection_Multiclass_OverSampling_No_gender.csv', index_col = 0)\n",
    "            filtering = Feature_Selection[(Feature_Selection['gender'] == ii) & (Feature_Selection['age'] == str(age_list[age]))]\n",
    "            column_feature = ['HE_BMI'] + list(filtering.index[0:top_count])\n",
    "            \n",
    "            \n",
    "            data_select = data_copy[column_feature].copy()\n",
    "            data_select2 = data2_copy[column_feature].copy()\n",
    "            data_select3 = data3_copy[column_feature].copy()\n",
    "            data_select4 = data4_copy[column_feature].copy()\n",
    "            for i in range(len(column_feature)):\n",
    "                BMI_grade.append([])\n",
    "                ## 숫자로 바꿔주는 코드임.\n",
    "                data_select[column_feature[i]] = pd.to_numeric(data_select[column_feature[i]], errors='coerce').astype(float).round(2)\n",
    "                data_select2[column_feature[i]] = pd.to_numeric(data_select2[column_feature[i]], errors='coerce').astype(float).round(2)\n",
    "                data_select3[column_feature[i]] = pd.to_numeric(data_select3[column_feature[i]], errors='coerce').astype(float).round(2)\n",
    "                data_select4[column_feature[i]] = pd.to_numeric(data_select4[column_feature[i]], errors='coerce').astype(float).round(2)            #print(len(df)) #16000개\n",
    "                \n",
    "\n",
    "            df1 = data_select[column_feature]\n",
    "            df2 = data_select2[column_feature]\n",
    "            df3 = data_select3[column_feature]\n",
    "            df4 = data_select4[column_feature]\n",
    "            \n",
    "            df = pd.concat([df1, df2, df3, df4], ignore_index=True) # 18년 19년 자료 합쳐주는 부분.\n",
    "            df = df.dropna(how = 'any')\n",
    "            df = df.sort_values(by = 'HE_BMI')\n",
    "            for i in range(len(column_feature)):\n",
    "                ### 8,9제거\n",
    "                if column_feature[i] in list999:\n",
    "                    df.drop(df[(df[column_feature[i]] == 888) | (df[column_feature[i]] == 999)].index, inplace = True)\n",
    "                elif column_feature[i] in list88:\n",
    "                    df.drop(df[(df[column_feature[i]] == 88) | (df[column_feature[i]] == 99)].index, inplace = True)\n",
    "                else:\n",
    "                    df.drop(df[(df[column_feature[i]] == 8) | (df[column_feature[i]] == 9)].index, inplace = True)\n",
    "\n",
    "            BMI_tmp = df['HE_BMI']\n",
    "            for k in range(len(df)): #여기서 문제가 생기는구나. 어떡할까\n",
    "                # print(i+cl*(ii-1)+len(age_list)*(age))\n",
    "                if BMI_tmp.iloc[k] < 23:\n",
    "                    BMI_grade[iter].append(0)\n",
    "                elif 23 <= BMI_tmp.iloc[k] < 25:\n",
    "                    BMI_grade[iter].append(1)\n",
    "                elif 25 <= BMI_tmp.iloc[k]:\n",
    "                    BMI_grade[iter].append(2)\n",
    "            tree_data = df.drop(['HE_BMI'],axis = 1)\n",
    "            \n",
    "            \n",
    "            iteration_test.append([iter,ct])\n",
    "            if tree_data.empty == False:\n",
    "                #########################################################\n",
    "                # data normalizaion\n",
    "                min_max_scaler = preprocessing.MinMaxScaler()\n",
    "                x_scaled = min_max_scaler.fit_transform(tree_data)\n",
    "                tree_data = pd.DataFrame(x_scaled,columns=tree_data.columns)\n",
    "                tree_data['BMI_grade'] = BMI_grade[iter]\n",
    "\n",
    "                X = tree_data.iloc[:,:-1]\n",
    "                y = tree_data.iloc[:,-1:]\n",
    "                # y = y.squeeze()\n",
    "\n",
    "                # from sklearn.preprocessing import label_binarize\n",
    "                # y = label_binarize(y, classes=[0, 1, 2])\n",
    "                n_classes = 3 #고정\n",
    "                \n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "\n",
    "\n",
    "                cnt_dict = dict(Counter(y_train['BMI_grade']))\n",
    "                cnt0 = cnt_dict[0]\n",
    "                cnt1 = cnt_dict[1]\n",
    "                cnt2 = cnt_dict[2]\n",
    "                print(cnt0, cnt1, cnt2)\n",
    "\n",
    "                # #######################\n",
    "                # ###### MANUALLY #######\n",
    "                # #######################\n",
    "                                \n",
    "                # cnt_max = max(cnt0,cnt1,cnt2)\n",
    "                # train_ = pd.concat([X_train, y_train], axis=1)\n",
    "                \n",
    "                # n_resampl_0 = cnt_max - cnt0\n",
    "                # if n_resampl_0 != 0:\n",
    "                #     local = train_.loc[(train_['BMI_grade']==0)] #0인 갯수가 부족하니까 그것들을 추출\n",
    "                #     idx = local.index.values # 추출한 것의 index\n",
    "                #     select_list = [random.choice(idx) for i in range(n_resampl_0)] #랜덤으로 추출된 idx들 모음\n",
    "                #     tree_data_2 = train_.loc[select_list]\n",
    "                #     train_ = pd.concat([train_,tree_data_2], ignore_index=True)\n",
    "                \n",
    "                # n_resampl_1 = cnt_max - cnt1\n",
    "                # if n_resampl_1 != 0:\n",
    "                #     local = train_.loc[(train_['BMI_grade']==1)]\n",
    "                #     idx = local.index.values # 추출한 것의 index\n",
    "                #     select_list = [random.choice(idx) for i in range(n_resampl_1)] #랜덤으로 추출된 idx들 모음\n",
    "                #     tree_data_2 = train_.loc[select_list]\n",
    "                #     train_ = pd.concat([train_,tree_data_2], ignore_index=True)\n",
    "                \n",
    "                # n_resampl_2 = cnt_max - cnt2\n",
    "                # if n_resampl_2 != 0:\n",
    "                #     local = train_.loc[(train_['BMI_grade']==2)]\n",
    "                #     idx = local.index.values # 추출한 것의 index\n",
    "                #     select_list = [random.choice(idx) for i in range(n_resampl_2)] #랜덤으로 추출된 idx들 모음\n",
    "                #     tree_data_2 = train_.loc[select_list]\n",
    "                #     train_ = pd.concat([train_,tree_data_2], ignore_index=True)\n",
    "                \n",
    "                # X_train = train_.iloc[:,:-1]\n",
    "                # y_train = train_.iloc[:,-1:]\n",
    "\n",
    "                ###############\n",
    "                ### SMOTE #####\n",
    "                ###############\n",
    "                sm = SMOTE(random_state=12)#, ratio = 1.0)\n",
    "                X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "                \n",
    "                cnt_dict = dict(Counter(y_train['BMI_grade']))\n",
    "                cnt0 = cnt_dict[0]\n",
    "                cnt1 = cnt_dict[1]\n",
    "                cnt2 = cnt_dict[2]\n",
    "                print('after augmentation')\n",
    "                print(cnt0, cnt1, cnt2)\n",
    "                print('------------------')\n",
    "                ##########################################################\n",
    "                clf = LogisticRegression(multi_class='ovr')\n",
    "                parameters = { \"penalty\" : [\"l2\", \"l1\"], \"C\" : [0.01, 0.1, 1, 5, 10] }\n",
    "                ##################GRID SEARCH CV\n",
    "                # parameters = {'gamma':[0.01, 0.1,0.5,1,5,10,30,50],\n",
    "                #             'C':[0.01, 0.1,0.5,1,5,10,30,50]}\n",
    "                grid_dtree = GridSearchCV(clf,param_grid=parameters,cv=3,refit=True)\n",
    "                grid_dtree.fit(X_train,y_train)\n",
    "\n",
    "                print('GridSearchCV 최적 파라미터:', grid_dtree.best_params_)\n",
    "                print('GridSearchCV 최고 정확도: {0:.4f}'.format(grid_dtree.best_score_))\n",
    "\n",
    "                fig = plt.figure(2*i)\n",
    "                # results = pd.DataFrame(grid_dtree.cv_results_)\n",
    "                # scores = np.array(results.mean_test_score).reshape(8, 8)\n",
    "                # /mg.tools.heatmap(scores, xlabel='gamma', xticklabels=parameters['gamma'],ylabel='C', yticklabels=parameters['C'], cmap=\"viridis\")\n",
    "                best_param = list(grid_dtree.best_params_.values())\n",
    "                # plt.title(grid_dtree.best_params_.items())\n",
    "                # plt.savefig(PATH + '/top ' + str(top_count) + ' ' + str(ii) + ' ' + str(age_list[age]) + ' ' + str(i+1) + \"_\" + 'Heatmap' + \".png\", dpi=300)\n",
    "                # plt.close()\n",
    "                # plt.show()\n",
    "\n",
    "                clf = LogisticRegression(penalty = best_param[1], C = best_param[0], max_iter=1000, multi_class='ovr', solver='lbfgs')\n",
    "                clf.fit(X_train,y_train.values.ravel())\n",
    "                y_pred = clf.predict(X_test) \n",
    "\n",
    "                r_score = recall_score(y_test, y_pred, average = 'micro')\n",
    "                p_score = precision_score(y_test, y_pred, average = 'micro')\n",
    "                f_score = f1_score(y_test, y_pred, average = 'micro')\n",
    "                accuracy = clf.score(X_test,y_test)#, average = None)\n",
    "                # TP = perf_measure(np.array(y_test), y_pred)[0]\n",
    "                # FP = perf_measure(np.array(y_test), y_pred)[1]\n",
    "                # TN = perf_measure(np.array(y_test), y_pred)[2]\n",
    "                # FN = perf_measure(np.array(y_test), y_pred)[3]\n",
    "                \n",
    "                print_list.append([])\n",
    "                print_list[ct].append(str(sex))\n",
    "                print_list[ct].append(str(age_list[age]))\n",
    "                print_list[ct].append(str(column_feature))\n",
    "                print_list[ct].append(str(cnt0))\n",
    "                print_list[ct].append(str(cnt1))\n",
    "                print_list[ct].append(str(cnt2))\n",
    "                \n",
    "                print_list[ct].append(np.round(accuracy,3))\n",
    "                print_list[ct].append(np.round(r_score,3))\n",
    "                print_list[ct].append(np.round(p_score,3))\n",
    "                print_list[ct].append(np.round(f_score,3))\n",
    "                \n",
    "\n",
    "                # Compute ROC curve and ROC area for each class\n",
    "                fpr = dict()\n",
    "                tpr = dict()\n",
    "                roc_auc = dict()\n",
    "                \n",
    "                y_test = label_binarize(y_test, classes=[0, 1, 2]) # SVC input이 one hot incoding으로 안들어감.\n",
    "                \n",
    "                for i in range(n_classes):\n",
    "                    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], clf.predict_proba(X_test)[:, 1])\n",
    "                    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "                \n",
    "                # Compute micro-average ROC curve and ROC area\n",
    "                fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), clf.predict_proba(X_test).ravel())\n",
    "                roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "                lw = 2\n",
    "                \n",
    "                # First aggregate all false positive rates\n",
    "                all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "                # Then interpolate all ROC curves at this points\n",
    "                mean_tpr = np.zeros_like(all_fpr)\n",
    "                for i in range(n_classes):\n",
    "                    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "                # Finally average it and compute AUC\n",
    "                mean_tpr /= n_classes\n",
    "\n",
    "                fpr[\"macro\"] = all_fpr\n",
    "                tpr[\"macro\"] = mean_tpr\n",
    "                roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "                # Plot all ROC curves\n",
    "                plt.figure(figsize=(9,9))\n",
    "                plt.plot(\n",
    "                    fpr[\"micro\"],\n",
    "                    tpr[\"micro\"],\n",
    "                    label=\"micro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"micro\"]),\n",
    "                    color=\"deeppink\",\n",
    "                    linestyle=\":\",\n",
    "                    linewidth=4,\n",
    "                )\n",
    "\n",
    "                plt.plot(\n",
    "                    fpr[\"macro\"],\n",
    "                    tpr[\"macro\"],\n",
    "                    label=\"macro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"macro\"]),\n",
    "                    color=\"navy\",\n",
    "                    linestyle=\":\",\n",
    "                    linewidth=4,\n",
    "                )\n",
    "\n",
    "                colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\"])\n",
    "                for i, color in zip(range(n_classes), colors):\n",
    "                    plt.plot(\n",
    "                        fpr[i],\n",
    "                        tpr[i],\n",
    "                        color=color,\n",
    "                        lw=lw,\n",
    "                        label=\"ROC curve of class {0} (area = {1:0.2f})\".format(i, roc_auc[i]),\n",
    "                    )\n",
    "\n",
    "                plt.plot([0, 1], [0, 1], \"k--\", lw=lw)\n",
    "                plt.xlim([0.0, 1.0])\n",
    "                plt.ylim([0.0, 1.05])\n",
    "                plt.xlabel(\"False Positive Rate\", fontsize=20)\n",
    "                plt.ylabel(\"True Positive Rate\", fontsize=20)\n",
    "                plt.title(\"Top \" + str(top_count)\n",
    "                            + \" \" + str(age_list[age])\n",
    "                            + \" \" + str(ii) + ' Multiclass ROC', fontsize=20)\n",
    "                plt.legend(loc=\"lower right\", fontsize=15)\n",
    "                plt.savefig(PATH +\"/Top \" + str(top_count)\n",
    "                            + \" \" + str(age_list[age])\n",
    "                            + \" \" + str(ii) + ' ROC-CURVE' + sup + '.png')\n",
    "                plt.show()\n",
    "                from sklearn.model_selection import cross_val_predict\n",
    "                from sklearn.metrics import confusion_matrix\n",
    "                y_train_pred = cross_val_predict(clf, X_train, y_train.values.ravel())\n",
    "                conf_mx = confusion_matrix(y_train.values.ravel(), y_train_pred)\n",
    "                plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "                plt.savefig(PATH +\"/Top \" + str(top_count)\n",
    "                            + \" \" + str(age_list[age])\n",
    "                            + \" \" + str(ii) + ' confusion-matrix' + sup + '.png')\n",
    "                y_prob = clf.predict_proba(X_test).ravel()\n",
    "                macro_roc_auc_ovo = roc_auc_score(y_test.ravel(), y_prob, multi_class=\"ovo\", average=\"macro\")\n",
    "                weighted_roc_auc_ovo = roc_auc_score(\n",
    "                    y_test.ravel(), y_prob, multi_class=\"ovo\", average=\"weighted\"\n",
    "                )\n",
    "                micro_roc_auc_ovo = roc_auc_score(\n",
    "                    y_test.ravel(), y_prob, multi_class=\"ovo\", average=\"micro\"\n",
    "                )\n",
    "                macro_roc_auc_ovr = roc_auc_score(y_test.ravel(), y_prob, multi_class=\"ovr\", average=\"macro\")\n",
    "                weighted_roc_auc_ovr = roc_auc_score(\n",
    "                    y_test.ravel(), y_prob, multi_class=\"ovr\", average=\"weighted\"\n",
    "                )\n",
    "                micro_roc_auc_ovr = roc_auc_score(\n",
    "                    y_test.ravel(), y_prob, multi_class=\"ovr\", average=\"micro\"\n",
    "                )\n",
    "                print(\n",
    "                    \"One-vs-One ROC AUC scores:\\n{:.6f} (macro),\\n{:.6f} \"\n",
    "                    \"(weighted by prevalence)\".format(macro_roc_auc_ovo, weighted_roc_auc_ovo)\n",
    "                )\n",
    "                print(\n",
    "                    \"One-vs-Rest ROC AUC scores:\\n{:.6f} (macro),\\n{:.6f} \"\n",
    "                    \"(weighted by prevalence)\".format(macro_roc_auc_ovr, weighted_roc_auc_ovr)\n",
    "                )\n",
    "                \n",
    "                print_list[ct].append(np.round(macro_roc_auc_ovo,3))\n",
    "                print_list[ct].append(np.round(micro_roc_auc_ovo,3))\n",
    "                print_list[ct].append(np.round(weighted_roc_auc_ovo,3))\n",
    "                print_list[ct].append(np.round(macro_roc_auc_ovr,3))\n",
    "                print_list[ct].append(np.round(micro_roc_auc_ovo,3))\n",
    "                print_list[ct].append(np.round(weighted_roc_auc_ovr,3))\n",
    "                \n",
    "                ct += 1\n",
    "                \n",
    "            iter += 1\n",
    "            \n",
    "            \n",
    "    pl = pd.DataFrame(print_list,\n",
    "                        columns=['gender',\n",
    "                                '<= age <',\n",
    "                                # \"group\",\n",
    "                                \"list\",\n",
    "                                'Number Of 0',\n",
    "                                'Number of 1',\n",
    "                                'Number of 2',\n",
    "                                'accuracy score',\n",
    "                                'recall score',\n",
    "                                'precision score',\n",
    "                                'f1 score',\n",
    "                                'OVO AUC macro',\n",
    "                                'OVO AUC micro',\n",
    "                                'OVO AUC weighted',\n",
    "                                'OVR AUC macro',\n",
    "                                'OVR AUC micro',\n",
    "                                'OVR AUC weighted'])\n",
    "\n",
    "    pl.to_csv(PATH + '/top ' + str(top_count) + ' LR_혈액검사 데이터' + sup + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ass"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c7ac97df0b9ce11aa8fedd52ebf62a0bf09db6b153f6fca506b128f66bce1468"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit ('.venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "b34de1f8e6b4ea2f6cd2f3afdb0accdfa84388fc779c4716220242f4f659a80f"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
